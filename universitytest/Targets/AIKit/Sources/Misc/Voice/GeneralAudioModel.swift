//
//  GeneralAudioModel.swift
//  AIKit (Generated by SwiftyLaunch 1.5.0)
//  https://docs.swiftylaun.ch/module/aikit/ai-translator-example
//

import AVFoundation
import AnalyticsKit
import Foundation
import SharedKit

class GeneralAudioModel {

	var audioPlayer: AVAudioPlayer!
	var audioSession: AVAudioSession = AVAudioSession.sharedInstance()

	/// Will play an audio file from a passed Data object
	///- Parameter data: The Data object containing the audio file
	///- Parameter fileFormat: The file format of the audio file (we record in m4a, but the server returns mp3)
	func playAudio(from data: Data, fileFormat: String = "m4a") {

		Analytics.capture(.info, id: "start_playing_audio", source: .aikit)

		do {
			try audioSession.setCategory(.playback, options: [.mixWithOthers])
			try audioSession.setActive(true)
			audioPlayer = try AVAudioPlayer(data: data, fileTypeHint: fileFormat)
			guard let player = audioPlayer else { return }
			player.prepareToPlay()
			player.play()
		} catch {
			showInAppNotification(
				.error, content: .init(title: "Failed to Play Audio", message: "Audio Playback Error 2"))
			Analytics.capture(
				.error, id: "playing_audio", longDescription: "Error: \(error.localizedDescription)",
				source: .aikit)
		}
	}

	/// Wrapper of the playAudio function that also takes a base64 string as input
	func playAudio(base64Source: String) {
		guard let data = Data(base64Encoded: base64Source) else {
			showInAppNotification(
				.error, content: .init(title: "Failed to Play Audio", message: "Audio Playback Error 3"))
			return
		}
		playAudio(from: data)
	}

}
