//
//  VoiceTranscriptionModel.swift
//  AIKit (Generated by SwiftyLaunch 1.5.0)
//  https://docs.swiftylaun.ch/module/aikit/ai-translator-example
//

import AnalyticsKit
import AudioKit
import Foundation
import SwiftWhisper

// The View Name for Analytics Capture
private let viewName = "VoiceTranscriptionModel"

// This model utilizes a pre-trained model to transcribe audio files to text called whisper.
// The model is trained to be lightweight and recognize a variety of languages.
// More information on the model: https://huggingface.co/ggerganov/whisper.cpp

class VoiceTranscriptionModel: ObservableObject {

	@Published var currentAudioTranscription: String? = nil

	/// Speech -> Text. Returns nil if there was an error
	func transcribeAudio(fromURL audioDataURL: URL) async throws -> String {

		Analytics.capture(.info, id: "start_transcribing_audio", source: .aikit, fromView: viewName)

		let whisperModelURL = Bundle.module.url(forResource: "ggml-tiny", withExtension: "bin")!
		let whisper = Whisper(fromFileURL: whisperModelURL)

		let pcmAudioFrames = try await convertAudioFileToPCMArray(audioFileURL: audioDataURL)
		let segments = try await whisper.transcribe(audioFrames: pcmAudioFrames)
		return segments.map(\.text).joined()
	}

	@available(*, renamed: "convertAudioFileToPCMArray(audioFileURL:)")
	func convertAudioFileToPCMArray(audioFileURL: URL, completionHandler: @escaping (Result<[Float], Error>) -> Void) {

		Analytics.capture(.info, id: "start_converting_audio_file_to_pcm_array", source: .aikit, fromView: viewName)

		var options = FormatConverter.Options()
		options.format = .wav
		options.sampleRate = 16000  // should be 16kHz PCM
		options.bitDepth = 16
		options.channels = 1
		options.isInterleaved = false

		let tempURL = URL(fileURLWithPath: NSTemporaryDirectory()).appendingPathComponent(UUID().uuidString)
		let converter = FormatConverter(inputURL: audioFileURL, outputURL: tempURL, options: options)

		converter.start { error in
			if let error {
				Analytics.capture(
					.error, id: "converting_audio_file_to_pcm_array",
					longDescription: "Error: \(error.localizedDescription)", source: .aikit,
					fromView: viewName)
				completionHandler(.failure(error))
				return
			}

			let data = try! Data(contentsOf: tempURL)

			let floats = stride(from: 44, to: data.count, by: 2).map {
				return data[$0..<$0 + 2].withUnsafeBytes {
					let short = Int16(littleEndian: $0.load(as: Int16.self))
					return max(-1.0, min(Float(short) / 32767.0, 1.0))
				}
			}

			try? FileManager.default.removeItem(at: tempURL)

			completionHandler(.success(floats))
		}
	}

	/// Async wrapper of the function above
	func convertAudioFileToPCMArray(audioFileURL: URL) async throws -> [Float] {
		return try await withCheckedThrowingContinuation { continuation in
			convertAudioFileToPCMArray(audioFileURL: audioFileURL) { result in
				continuation.resume(with: result)
			}
		}
	}

}
