//
//  VoiceRecordingManager.swift
//  AIKit (Generated by SwiftyLaunch 1.5.0)
//  https://docs.swiftylaun.ch/module/aikit/ai-translator-example
//

import AVFAudio
import AnalyticsKit
import SharedKit
import SwiftUI

class VoiceRecordingManager: NSObject, ObservableObject, AVAudioRecorderDelegate {

	var audioSession: AVAudioSession = AVAudioSession.sharedInstance()

	var audioRecorder: AVAudioRecorder!

	@ObservedObject var voiceTranscriptionModel = VoiceTranscriptionModel()

	/// Will start an audio session that records audio and saves it in the path defined in getTempRecordingPath()
	/// Make sure that you already have the permission to record audio before calling this (via askUserFor(.microphoneAccess) for example)
	func startRecording() {
		print("[VOICE RECORDING MANAGER]: START RECORDING")
		Analytics.capture(.info, id: "voice_recording_manager_start_recording", source: .aikit)
		do {
			try audioSession.setCategory(.playAndRecord, mode: .default)
			try audioSession.setActive(true)

			let settings = [
				AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
				AVSampleRateKey: 44100,
				AVNumberOfChannelsKey: 1,
				AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue,
			]

			audioRecorder = try AVAudioRecorder(url: getTempRecordingPath(), settings: settings)
			audioRecorder.delegate = self
			audioRecorder.record()
		} catch {
			Analytics.capture(
				.error, id: "voice_recording_manager_start_recording",
				longDescription: "Error Description: \(error.localizedDescription)", source: .aikit)
			///In case of an error, stop the recording
			stopRecording(success: false)
		}
	}

	/// Stops the Audio Recording
	/// Called either by the user when he engages with the shutter button or by the system in case of an error
	///- Parameter success: False indicates that the recording was stopped due to an error
	func stopRecording(success: Bool) {
		print("[VOICE RECORDING MANAGER]: STOP RECORDING")
		Analytics.capture(.info, id: "voice_recording_manager_stoprecording", source: .aikit)
		if !success {
			showInAppNotification(
				.failure, content: .init(title: "Failed to Record", message: "Audio Recording Error"))
		}
		if audioRecorder == nil { return }
		audioRecorder.stop()
		audioRecorder = nil

		if success {
			Task {
				do {
					let transcribedAudio = try await voiceTranscriptionModel.transcribeAudio(
						fromURL: getTempRecordingPath())
					voiceTranscriptionModel.currentAudioTranscription = transcribedAudio

					Analytics.capture(
						.info, id: "voice_recording_transcription_result",
						longDescription: "\(transcribedAudio)", source: .aikit)

				} catch {
					Analytics.capture(
						.error, id: "voice_recording_transcription",
						longDescription: "Error Transcribing Audio: \(error.localizedDescription)",
						source: .aikit)

					showInAppNotification(
						.error,
						content: .init(
							title: "Audio Recording Error", message: "Internal Audio Recording Error")
					)
				}
			}
		}
	}

	///Path for temporary storage of current Audio Recording
	func getTempRecordingPath() -> URL {
		let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
		return paths[0].appendingPathComponent("recording.m4a")
	}
}
